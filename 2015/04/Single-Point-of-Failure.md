# 聊聊【单点故障】——关于“德国空难”和“李光耀”的随想 

-----

<div class="post-body entry-content">
　　前不久的两个热点新闻分别是：3月23日新加坡的李光耀死了，3月24日德国发生了空难。这两件事挨得很近，所以当俺看到这俩新闻的时候，“单点故障”这个词汇就在脑海中浮现。今天跟大伙儿聊聊与“单点故障”相关的话题。<br/>
<a name="more"></a><br/>
<br/>
<h2>★啥是“单点故障”？</h2><br/>
　　“单点故障”一词，洋文称为“Single Point of Failure”（缩写是“SPOF”）。<br/>
　　这个词汇貌似源自于 IT 行业，其大致意思是：系统中某个单一的环节出问题，会导致整个系统出现严重问题。<br/>
　　虽然是 IT 行业发明的词汇，但其实在各个学科、各个领域都可以看到“单点故障”的例子。比如这次德国空难，已经查明是副驾驶蓄意制造坠机。在这个案例中，如果你把整驾飞机看成是一个系统，那么“驾驶员”就是所谓的“单点”，当驾驶员蓄意制造空难，此人就成为“单点故障”。<br/>
　　如果某个系统中存在“单点”，但是尚未发生故障，则称之为“单点故障风险”。<br/>
<br/>
<br/>
<h2>★“单点故障”的特点</h2><br/>
　　还以德国空难为例。<br/>
　　一旦某个客机的飞行员企图人为制造空难，在这种情况下：<br/>
即使地面的安检再严格，也无助于事；<br/>
即使飞机的性能再优良，也无助于事；<br/>
即使飞机的结构再牢固，也无助于事；<br/>
即使飞机上配备了再多的反劫机保安，无助于事；<br/>
......<br/>
<br/>
　　从这个案例可以看出“单点故障”的特殊之处——<b>如果某个系统存在【单点】，即使系统的其它部分做得再完备，也【无法】降低单点故障造成的破坏性。</b><br/>
<br/>
<br/>
<h2>★“单点故障”的两种类型</h2><br/>
　　介绍完“单点故障”的特点，再来说说“单点故障”的两种类型（这两种类型，危险性是不同的）：<br/>
类型1：可以恢复<br/>
类型2：不可恢复<br/>
<br/>
　　这俩是啥意识捏？俺举2个例子：<br/>
　　假设你有一台日常使用的笔记本电脑，而且里面的数据【没有】备份。有一天，如果笔记本的内存条突然坏了，那么整个笔记本都没法用了（不可用）。但如果你找售后维修人员，帮你换一个内存条，那么这台笔记本又重新可以用了（可恢复）。<br/>
　　现在换一个假设：不是内存条坏掉，而是硬盘彻底坏了。这时候，笔记本同样处于不可用的状态。但更严重的是——即使你找售后维修人员帮你换了一个新硬盘，你也无法找回原先的数据。这就是所谓的“不可恢复”。<br/>
　　在这两个例子里：内存条导致的单点故障是“可恢复的”，而硬盘导致的单点故障是“不可恢复的”（除非你有“实时备份机制”）。<br/>
<br/>
　　很显然，后一类单点故障更加危险。<br/>
<br/>
<br/>
<h2>★各个行业/领域的【反面】教材</h2><br/>
<h3>◇政治领域的例子——独裁者/僭主</h3><br/>
　　既然在标题中提到了“李光耀”，所以俺首先拿“政治领域”来说事儿。<br/>
　　“李光耀”此人，争议很大，诽誉皆有。为了避免跑题，在这里，俺就不点评李光耀此人如何。不论是“李粉”还是“李黑”，想必都赞同一点——李光耀对新加坡的影响极大。别的不说，光看此人连任了30多年的总理。卸任总理之后，又当了21年的“资政”（14年国务资政，7年内阁资政）——单从这些数字，你就能体会到此人对新加坡的影响力（顺便说一下：如今新加坡总理李显龙是他的亲儿子）<br/>
　　从某种意义上说，李光耀俨然是新加坡的“僭主”（“僭主”是政治学术语，其解释参见《<a href="../../2012/07/form-of-government.md">政治常识扫盲：聊聊常见的政治体制</a>》，通俗地说，就是“独裁者”）。如果你把新加坡看成是一个系统，那么李光耀在过去几十年里，一直是这个系统中的“单点”。<br/>
　　不仅是李光耀，任何一个僭主，都是其所在国家的“单点”。<br/>
　　为了说明这点，再来举希特勒的例子。<br/>
　　很多人有一个误解——以为希特勒在1933年1月当选总理之后，就成了独裁者。其实不然。真正让希特勒成为独裁者的，是1933年3月的“授权法案”。<br/>
　　希特勒充分利用了1933年2月底发生的国会纵火案，大肆制造恐怖气氛，然后迫使议会通过了“授权法案”（法案的详情参见“<a href="https://zh.wikipedia.org/wiki/1933%E5%B9%B4%E5%BE%B7%E5%9C%8B%E6%8E%88%E6%AC%8A%E6%B3%95%E6%A1%88" rel="nofollow" target="_blank">这里</a>”）。这个法案相当于给希特勒开了一张政治上的空白支票。有了这个授权法案之后，总理（希特勒）及其内阁，可以不经过议会，直接行使“立法权”。从那之后，三权分立荡然无存。于是，德国境内再也没有任何政治势力可以阻止希特勒的疯狂。<br/>
<br/>
　　开头部分提到“单点故障”的两种类型。独裁者导致的单点故障，其类型通常是后者——不可恢复型。<br/>
　　除了希特勒的例子，再来说说毛腊肉发动的“文革”。文革期间，很多人被迫害致死（其中不乏精英知识分子），大量的古迹被砸烂（其中不乏国家级名胜），大量书籍被销毁（其中不乏古籍珍本、孤本）......<br/>
　　上述这些破坏，都是【不可恢复】的。<br/>
<br/>
　　经常听到朝廷喉舌以及某些五毛批评欧美民主政治的低效率。俺本人也承认：民主体制（相对于“个人独裁体制”）效率会有明显下降。但是这种效率的下降，换来的好处是——消除了“个人独裁者”这个“单点故障风险”。考虑到独裁者如果成为单点故障，其破坏性是非常大的。所以这种效率下降是值得付出的。<br/>
<br/>
<h3>◇经济领域的例子——把鸡蛋放在同一个篮子里</h3><br/>
　　在经济领域经常听到一句老话“不要把鸡蛋放在同一个篮子里”。<br/>
　　这句话在几个不同的层面都有体现。咱们先来聊聊国家层面。<br/>
　　有很多国家依靠的是“单一经济支柱”。比如冷战时期，古巴严重依赖蔗糖的出口。当时以苏联为首搞了一个“<a href="https://zh.wikipedia.org/wiki/%E7%BB%8F%E6%B5%8E%E4%BA%92%E5%8A%A9%E5%A7%94%E5%91%98%E4%BC%9A" rel="nofollow" target="_blank">经济互助委员会</a>”（简称“经互会”），其成员都是共产党国家。古巴也加入了“经互会”，专门负责出口蔗糖（苏联提供巨额补贴），然后换取石油和粮食。等到1989年之后，东欧巨变，苏联解体，“华约”和“经互会”纷纷解散，古巴一下子傻逼了——1989年到1992年，古巴的 GDP 猛降达 35% 之多。<br/>
　　古巴是过去的例子。如今的例子是俄罗斯。<br/>
　　俄罗斯的“单一经济支柱”也就是“石油出口”。所以最近1年，国际油价大跌，导致俄罗斯的卢布和外汇储备都跟着猛降（关于这事儿，俺还专门发过一期《<a href="../../2014/12/weekly-share-77.md">每周转载</a>》）。<br/>
<br/>
　　说完“国家层面”，再来说说个人/家庭层面。<br/>
　　生活在天朝的读者，应该都听说过“国营企业改制”。在“改制”的过程中，很多国营企业经过“重组、兼并、合资、管理层收购”。然后有大量的员工被裁员。有很多家庭，其家庭成员（夫妻、子女、女婿、儿媳）都在【同一个】工厂上班。一旦碰到裁员，整个家庭收入一下子陷入困境。<br/>
　　在这个例子里，所有家庭成员都在同一个机构工作，这本身就是一个巨大的“单点故障风险”。<br/>
<br/>
<h3>◇信息安全领域的例子——社会工程学</h3><br/>
　　（如果你不晓得啥是“社会工程学”，请看俺写的<a href="../../2009/05/social-engineering-0-overview.md">扫盲系列</a>）<br/>
　　作为俺的老本行，再来聊聊信息安全领域的话题。<br/>
　　很多政府机构以及很多的跨国大公司，都有非常完备的软硬件体系来确保整个机构信息系统的安全。比如在各个子网的边界部署防火墙，比如在每一台单机上部署杀毒软件，比如部署统一的安全监控/管理系统......<br/>
　　但是上述这些措施，如果遭遇“社会工程学”的攻击，都将变得不堪一击。<b>因为“社会工程学的攻击”，针对的是人性的弱点</b>。<br/>
　　在一个组织机构内部，不管你部署再多再牛逼的安全设备，也无法彻底消除【人性的弱点】。这时候，“人的因素”成为信息安全体系中的“单点”。<br/>
　　举例：<br/>
　　关于“斯诺登”和“棱镜门丑闻”，想必大伙儿都知道了。斯诺登后来接受采访，提到他是如何拿到 NSA（美国国安局）的那么多机密。一方面，他采用了某些技术手段（具体细节，以后有空再聊）；另一方面，他也采用“社会工程学”手段。比如，他以“系统管理员”的身份，向 NSA 的某些职员索要个人帐号密码。很多人都给他了。很显然，这些给斯诺登密码的人，缺乏足够的安全培训，不懂得防范“社会工程学”的风险。<br/>
　　顺便说一下，俺本人支持斯诺登的爆料——他捍卫了个人自由，反击大政府对隐私权的侵犯（说到侵犯隐私，咱们朝廷比美国政府更恶心）。<br/>
<br/>
<br/>
<h2>★各个行业/领域的【正面】教材</h2><br/>
　　前面提到的几个领域，都是反面教材——介绍系统中的某个因素如何成为“单点故障”。再来介绍一些正面教材——规避单点故障的例子。<br/>
<br/>
<h3>◇生物学领域的例子——生态圈的多样性</h3><br/>
　　生态圈中，不同的物种是通过“食物链”耦合在一起的。在食物链的每一个层次，都会有 N 个不同的物种。所以，单个物种的灭绝，并【不会】导致整个食物链崩溃。另外，如果你注意观察，大部分物种，都有不止一个的天敌。<br/>
　　从上述的介绍可以看出——生态圈充满了“多样性”。恰恰是这种“多样性”避免了“单点故障风险”。<br/>
<br/>
<h3>◇IT 领域的例子——网状拓扑结构</h3><br/>
　　咱们今天用的互联网，其前身是阿帕网（ARPANET），由美国国防部设计。<br/>
　　当初设计这玩意儿的目标之一是“抗核打击”（那会儿还在“美苏冷战”）。所以，阿帕网被设计成“网状结构”。在这种结构中，每个互联网节点都与其它的多个节点相连。万一发生核大战，即使有半数节点被摧毁，剩余的大多数节点还是有可能相互连接。<br/>
<br/>
<h3>◇军事领域的例子——阿帕奇部落</h3><br/>
　　白人刚踏上美洲大陆时，那里生活着非常多的印第安人，而且组织形态各异。在南美洲有非常庞大的<a href="https://zh.wikipedia.org/wiki/%E5%8D%B0%E5%8A%A0%E5%B8%9D%E5%9C%8B" rel="nofollow" target="_blank">印加帝国</a>，在墨西哥有同样庞大的<a href="https://zh.wikipedia.org/wiki/%E9%98%BF%E8%8C%B2%E7%89%B9%E5%85%8B" rel="nofollow" target="_blank">阿兹特克帝国</a>。这两个帝国虽然庞大，但是很快就被白人殖民者灭掉了（阿兹特克帝国于1521年灭亡，印加帝国1533年灭亡）。<br/>
　　与之对比，在北美洲的<a href="https://zh.wikipedia.org/wiki/%E9%98%BF%E5%B8%95%E5%A5%91%E6%97%8F" rel="nofollow" target="_blank">阿帕奇族</a>，是所有印第安部落中抗争最久的——到了19世纪后期，他们才向美国政府投降（那时的美国，已经是西方列强了）。<br/>
　　阿帕奇族从来就没有形成一个大帝国，而是始终处于松散的部落联盟形态。各个部落的酋长之间，【没有】隶属关系。每个部落都是各自为战。这种形态，反而很难彻底消灭——因为找不到明显的“单点故障”。<br/>
　　相比之下，印加帝国和阿兹特克帝国都是等级森严的大帝国。白人殖民者只要干掉或俘虏了最高统治者（皇帝），整个帝国瞬间瓦解。<br/>
<br/>
<br/>
<h2>★“单点故障”与“木桶原理”的异同</h2><br/>
　　在看本小节之前，某些聪明的读者或许已经意识到这两者的相似性。<br/>
　　“木桶原理”说的是：木桶的装水量取决于最短的那块木板。假设最短的木板长度为零，那么木桶的容量也变为零。这时候，木桶处于“不可用”的状态。这跟前面提到的某些“单点故障”的案例，有相似之处。<br/>
　　在本文开头，俺提到了“单点故障”的两种类型（“可恢复”与“不可恢复”）。极端情况下的木桶（某块木板长度为零）类似于第一类“单点故障”。换句话说，你可以用“木桶原理”来演示第一类单点故障；但是你【没法】用木桶原理来演示第二类单点故障。<br/>
<br/>
<br/>
<h2>★“单点故障”与“蝴蝶效应”的异同</h2><br/>
　　（某热心读者在评论中提到了“蝴蝶效应”，于是俺又补充了这一节）<br/>
　　从表面上，“蝴蝶效应”跟“单点故障”有某些相似之处——都是一个小小的因素产生了对系统的重大影响。<br/>
　　但其实，这两者的本质是完全不同的。<br/>
　　能够产生“蝴蝶效应”的系统是“混沌系统”，由于“混沌”，并不是每一只蝴蝶都能产生“蝴蝶效应”。如果某只蝴蝶之前曾经产生过混沌效应，之后未必能够再次产生。<br/>
　　与之相反，“单点”之所以成为“单点”，是由系统结构决定的。换句话说：单点所蕴含的“单点故障”是必然的，而不是偶然的。而且同一个单点有可能多次导致系统的“单点故障”。<br/>
<br/>
<br/>
<h2>★“单点故障”与“黑天鹅现象”的关系</h2><br/>
　　“黑天鹅现象”一词，源自塔勒布（Nassim Nicholas Taleb）所写的《<a href="https://docs.google.com/document/d/1KXiUCl08DMYrPqS2OhdjchI88-ZjUgl8d2yoctWJkKM/" target="_blank">黑天鹅——如何应对不可知的未来</a>》。此书写得很好，有兴趣的同学建议从头看完（<a href="https://github.com/programthink/books" target="_blank">俺的网盘</a>上有电子版）。<br/>
　　如果你没看过此书，俺大致解释一下：“黑天鹅现象”（也称“黑天鹅事件”）指的是那些“不可预测的、稀有的、影响巨大的事件”（比如 911事件）。<br/>
　　俺个人认为，有相当一部分“黑天鹅事件”跟“单点故障”有关。能够引发“黑天鹅事件”的“单点故障”，通常都非常隐蔽，以至于人们没有意识到该“单点”的存在。<br/>
　　比如“911事件”中倒塌的世贸双子塔，在当初设计的时候，已经考虑到“飞机撞击”的风险（因为早些年，帝国大厦曾经被飞机误撞过）。但是设计师【没有】考虑到大量航空燃油燃烧导致的风险（大量航空燃油产生的热量远远大于普通火灾，导致了双子塔中钢结构的破坏）。911当天，撞击双子塔的两架客机都是刚刚起飞，装满了航空燃油。<br/>
<br/>
　　稍微跑题一下，说说“911阴谋论”：<br/>
　　几乎每个重大事件发生后，都能在网上看到阴谋论的影子。911当然也不例外。俺举个阴谋论的反驳，作为例子。<br/>
　　某些阴谋论者称：钢筋的熔点是2700度左右，而航空燃油燃烧只能达到1500度左右，所以不足以让钢筋熔化。<br/>
　　但是捏，那些学过“材料力学/金属力学/建筑力学”的同学，会对这种质疑表示不屑——早在温度达到钢筋熔点之前，钢筋的强度就已经显著下降了。<br/>
　　（补充：另有若干读者在本文留言，指出钢筋的熔点并没有这么高。这是阴谋论质疑的又一个破绽）<br/>
<br/>
　　很多基于阴谋论的质疑，都如同上述这个——企图以外行的立场来质疑某个细节，进而质疑整个事件的真实性。<br/>
　　（关于阴谋论，俺曾经写过一篇《<a href="../../2011/11/conspiracy-theory.md">聊聊【阴谋论】流行的原因及其弊端</a>》，有兴趣的同学可以参考）<br/>
<br/>
<br/>
<h2>★“单点故障”的防范措施</h2><br/>
<h3>◇多样化/多元化</h3><br/>
　　前面提到“国企改制”过程中，某些家庭的遭遇。这些家庭出问题的根源在于——家庭成员的收入来源太过单一化。<br/>
　　从这个例子反过来思考，就可以发现应对“单点故障”的措施之一——多元化/多样化。<br/>
　　前面提到生态圈的健壮性，同样也是基于“多样化”。<br/>
<br/>
<h3>◇备用系统</h3><br/>
　　在 IT 行业搞过系统管理或运维的同学，应该都知道“双机热备”。顾名思义就是：同时运行两台服务器，万一某台坏了，还有另一台。<br/>
　　这个原理，其实也可以应用到其它领域。<br/>
　　举例：<br/>
　　在现实生活中，夫妻两人都带了家里的钥匙。万一哪天某人忘记带钥匙了，还可以依靠另一个人的钥匙开门。<br/>
<br/>
<h3>◇备用计划（Plan B）</h3><br/>
　　和“备用系统”类似的措施是“备用计划”。当你要做一些重要的事情或重要的决策，【不要】只考虑一套方案——至少你要留一个备选方案。<br/>
　　现实生活中，总是充满了各种小意外。因此，再怎么精密的计划，都可能出现始料未及的纰漏。如果某个纰漏足够严重，会让你的计划流产。如果你事先准备了“B计划”，就不至于太尴尬。<br/>
<br/>
<h3>◇系统化思考</h3><br/>
　　前面说的这几条，相对而言都比较容易搞定（至少是比较容易想到）。最难的大概是“系统化思考”。<br/>
　　大部分人在考察一个系统的时候，往往陷入“只见树木不见森林”的认知缺陷。在这种局限下，许多“单点故障风险”你是无法察觉的。<br/>
　　而“系统化思考”要求你具备“既见树木又见森林”的能力，你还要能察觉到：系统各个组成部分之间是如何互动的（正反馈、负反馈）。如果能做到这点，就可以察觉到更多的“单点故障风险”。<br/>
　　关于“系统化思考”，限于篇幅，就不展开了。推荐大伙儿去看《<a href="https://docs.google.com/document/d/1gmi62blYo0EEs5-XFPjAZEVlv-lK0gQWqIZSX7t9c0s/" target="_blank">第五项修炼——学习型组织的艺术和实务</a>》一书。此书是很经典的管理学名著（已经上传到<a href="https://github.com/programthink/books" target="_blank">俺的网盘</a>），书中提及的“5项修炼”分别是：自我超越、心智模式、共同愿景、团队学习、系统思考。最后这项修炼，是此书的重点/精华。<br/>
<br/>
<br/>
<h2>★“防范措施”的【局限性】</h2><br/>
　　虽然刚才提到了一些单点故障的防范措施，但是有必要在结尾说一个悲观的论点——当某个系统的规模达到一定的程度，你有可能永远做不到“消除【所有】单点”。<br/>
　　因为每个人的知识结构都是有局限性的，思维能力也是有局限性的。当系统的复杂性达到一定程度，必定会有一些“单点”处于所有人的盲区。如果这个系统的影响力足够大，当其中某个不为人知的单点发生故障，就会引发一次黑天鹅事件。<br/>
<br/>
　　更具有讽刺意味的是：如果某个系统极度复杂。即使系统中发生了单点故障，你甚至在【事后】都无法找出“单点”在哪儿？<br/>
　　举例：<br/>
　　1987年10月19日是全球金融史上有名的“黑色星期一”。那天全球股市（北美、欧洲、亚洲）全都暴跌。当时暴跌的情况之严重，以至于香港联交所宣布10月20日至10月23日，股市及期市停止交易四天（香港史上从未有过）。<br/>
　　股灾本身不奇怪，奇怪的是：在那天之前，没有任何重大的利空消息发布。<br/>
　　此事已经过去快30年了，至今对暴跌的起因，依然众说纷纭。维基百科的“<a href="https://zh.wikipedia.org/wiki/%E9%BB%91%E8%89%B2%E6%98%9F%E6%9C%9F%E4%B8%80" rel="nofollow" target="_blank">这个页面</a>”给出其中5种比较有名的解释。但这些都仅仅是猜测，真相依然未知。<br/>
　　为啥会这样捏？因为“全球金融市场”已经太大太复杂了。在人类社会中，很少有哪个系统的复杂性会超过它。这个系统中必定隐藏了很多无人知晓的单点。而且金融系统本身就具有很多“正反馈机制”，会把单点故障产生的影响力成倍放大。再加上全球金融市场每秒钟的交易量都是海量的。即使有人想做“事后调查”，面对的任务也如同“大海捞针”。<br/>
<br/>
<br/>
<b>俺博客上，和本文相关的帖子（需翻墙）</b>：<br/>
《<a href="../../2018/12/Book-Review-Antifragile-Things-That-Gain-from-Disorder.md">读书笔记：＜反脆弱——从不确定性中获益＞</a>》<br/>
《<a href="../../2014/09/oversimplification.md">各种【一元化思维】的谬误——从“星座理论”到“共产主义社会”</a>》<br/>
《<a href="../../2010/07/silent-proof.md">思维的误区：忽视沉默的大多数</a>》<br/>
《<a href="../../2009/07/book-review-are-your-lights-on.md">书评：＜你的灯亮着吗？——找到问题的真正所在＞</a>》<br/>
《<a href="../../2012/07/form-of-government.md">政治常识扫盲：聊聊常见的政治体制</a>》<br/>
《<a href="../../2009/05/social-engineering-0-overview.md">社会工程学扫盲</a>》（系列）<br/>
《<a href="../../2011/11/conspiracy-theory.md">聊聊【阴谋论】流行的原因及其弊端</a>》
</div>


------------------------------------------------

版权声明本博客所有的原创文章，作者皆保留版权。转载必须包含本声明，保持本文完整，并以超链接形式注明作者编程随想和本文原始地址：https://program-think.blogspot.com/2015/04/Single-Point-of-Failure.html
